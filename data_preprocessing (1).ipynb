{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOR5eG9QMBtYIhAUS7ndtFx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Need to upload:\n","*   shape_predictor_81_face_landmarks.dat\n","*   mask_detect.h5\n","*   videos\n","\n","\n","\n","\n"],"metadata":{"id":"lPrVnYwVlN_y"}},{"cell_type":"code","source":["import cv2\n","import os\n","import zipfile\n","import shutil\n","from sklearn.model_selection import train_test_split\n","from google.colab import files\n","import requests\n","from google.colab.patches import cv2_imshow\n"],"metadata":{"id":"VA512XT0gh1W"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Face detection using Haar Cascades"],"metadata":{"id":"O7n0AszGlFxP"}},{"cell_type":"code","source":["def face_detector(img):\n","    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    face_classifier = cv2.CascadeClassifier(os.path.join(cv2.data.haarcascades, 'haarcascade_frontalface_default.xml'))\n","    scale = 4.0\n","    faces = face_classifier.detectMultiScale(gray_img, scale, 5)\n","    # print(\"LEN: \", len(faces))\n","\n","    if len(faces) > 0:\n","      for (x, y, w, h) in faces:\n","          roi = img[y:y+h, x:x+w]\n","          return roi\n","    if len(faces) <= 0:\n","      scale = scale - 0.1\n","      while scale > 1.1:\n","        # print(\"Nie ma twarzy, scala: \", scale)\n","        faces = face_classifier.detectMultiScale(gray_img, scale, 5)\n","        if len(faces) > 0:\n","          for (x, y, w, h) in faces:\n","              roi = img[y:y+h, x:x+w]\n","              return roi\n","        scale = scale - 0.1\n","\n","\n","    return None\n"],"metadata":{"id":"b3V1IOYnuoJV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extracting the upper facial region when the lower part is obscured by a mask"],"metadata":{"id":"G_B4MHe9l2x-"}},{"cell_type":"code","source":["predictor = dlib.shape_predictor(\"shape_predictor_81_face_landmarks.dat\")\n","\n","def extract_forehead_face(img):\n","    x,y =img.shape[0], img.shape[1]\n","    dlib_rect = dlib.rectangle(1,1,x-1,y-1)\n","    landmarks = predictor(img, dlib_rect)\n","\n","    forehead_face_roi = np.array([\n","        (landmarks.part(20).x, landmarks.part(20).y),  # Left brow\n","        (landmarks.part(25).x, landmarks.part(25).y),\n","        (landmarks.part(70).x, landmarks.part(70).y),  # Right brow\n","        (landmarks.part(71).x, landmarks.part(71).y),\n","        (landmarks.part(1).x, landmarks.part(1).y),    # Left side\n","        (landmarks.part(17).x, landmarks.part(17).y),  # Right side\n","        (landmarks.part(16).x, landmarks.part(16).y),\n","        (landmarks.part(6).x, landmarks.part(16).y),\n","        (landmarks.part(42).x, landmarks.part(42).y),  # Left eye bottom\n","        (landmarks.part(47).x, landmarks.part(47).y),  # Right eye bottom\n","    ], dtype=np.int32)\n","\n","    x, y, w, h = cv2.boundingRect(forehead_face_roi)\n","    new_y = max(0, int(y - 0.2 * h))\n","    new_h = int(h + 0.1 * h)\n","    forehead_face = img[new_y:new_y + new_h, x:x + w]\n","\n","    return forehead_face\n","\n","\n"],"metadata":{"id":"ODpTW8Q9iNVB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Detecting a mask and extracting upper part of the face\n"],"metadata":{"id":"6_Un4uQbmKeS"}},{"cell_type":"code","source":["loaded_model = load_model(\"mask_detect.h5\")\n","\n","def mask_detector(roi_img):\n","    resized_roi_img = cv2.resize(roi_img, (224, 224))\n","    normalized_roi_img = resized_roi_img / 255.0\n","    img_for_prediction = normalized_roi_img.reshape(1, 224, 224, 3)\n","    mask_prediction = loaded_model.predict(img_for_prediction)\n","    result = np.argmax(mask_prediction)\n","    if result == 0:\n","        # cv2.putText(img, 'Mask Detected', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n","        upper_face_roi = extract_forehead_face(roi_img)\n","\n","        return upper_face_roi\n","\n","    else:\n","        # cv2.putText(img, 'No Mask Detected', (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n","        print(\"no\")\n","        return roi_img\n"],"metadata":{"id":"G7TfXlI3iJu0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Extracting frames from videos, splitting into test and train data, saving into zip files"],"metadata":{"id":"zfgloKirmi6S"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"UBhPy8KYf86H"},"outputs":[],"source":["def extract_frames_and_process(video_paths, local_folder, output_folder, zip_filename):\n","    if not os.path.exists(local_folder):\n","        os.makedirs(local_folder)\n","\n","    image_id = 1\n","\n","    for vid in video_paths:\n","        success = True\n","        count = 1\n","\n","        video = cv2.VideoCapture(vid)\n","\n","        while success:\n","            success, frame = video.read()\n","\n","            if success == True:\n","                if count % 1 == 0:\n","                    name = f'{local_folder}/{image_id}.jpg'\n","                    cv2.imwrite(name, frame)\n","                    image_id += 1\n","                count += 1\n","            else:\n","                break\n","\n","    print(\"Total Extracted Frames:\", image_id)\n","    print(\"Frames saved to:\", local_folder)\n","\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    for filename in os.listdir(local_folder):\n","        if filename.endswith(\".jpg\"):\n","            img_path = os.path.join(local_folder, filename)\n","\n","            test_img = cv2.imread(img_path)\n","\n","\n","            roi = face_detector(test_img)\n","            roi = face_detector(test_img)\n","            if roi is not None:\n","                pred = mask_detector(roi)\n","\n","                if pred is not None and np.any(pred):\n","\n","                    output_path = os.path.join(output_folder, f\"{filename}\")\n","                    cv2.imwrite(output_path, pred)\n","                else:\n","                    print(f\"Empty or invalid pred for image: {img_path}\")\n","\n","    print(\"Total images processed:\", len(os.listdir(output_folder)))\n","\n","\n","    with zipfile.ZipFile(zip_filename, 'w') as zip_ref:\n","\n","        for filename in os.listdir(output_folder):\n","            if filename.endswith(\".jpg\"):\n","                img_path = os.path.join(output_folder, filename)\n","                zip_ref.write(img_path, arcname=filename)\n","\n","    print(f\"Images in {output_folder} saved to {zip_filename}\")\n","\n","    files.download(zip_filename)"]},{"cell_type":"code","source":["vid_paths=[\"SYLWIA_1.mp4\",\"SYLWIA_2.mp4\",\"SYLWIA_3.mp4\",\"SYLWIA_4.mp4\"]\n","extract_frames_and_process(vid_paths,\"Syl\",\"Syl_o\",\"syl_pred.zip\")"],"metadata":{"id":"x1cMOV0jikXZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_path = '/content/data/Dataset'\n","\n","classes = [\"Emilka\", \"Julka\", \"Kacper\", \"Kaja\", \"Karolina\", \"Kuba\", \"Maciek\", \"Madzia\", \"Ola\", \"Sylwia\", \"Szczepan\"]\n","\n","test_size = 0.2\n","random_seed = 42\n","\n","train_path = os.path.join(data_path, 'train')\n","test_path = os.path.join(data_path, 'test')\n","\n","os.makedirs(train_path, exist_ok=True)\n","os.makedirs(test_path, exist_ok=True)\n","\n","for class_name in classes:\n","    class_data_path = os.path.join(data_path, class_name)\n","\n","    files = os.listdir(class_data_path)\n","\n","    train_files, test_files = train_test_split(files, test_size=test_size, random_state=random_seed)\n","\n","    class_train_path = os.path.join(train_path, class_name)\n","    class_test_path = os.path.join(test_path, class_name)\n","\n","    os.makedirs(class_train_path, exist_ok=True)\n","    os.makedirs(class_test_path, exist_ok=True)\n","\n","    for file in train_files:\n","        shutil.move(os.path.join(class_data_path, file), os.path.join(class_train_path, file))\n","\n","    for file in test_files:\n","        shutil.move(os.path.join(class_data_path, file), os.path.join(class_test_path, file))\n","\n","sample_class = classes[0]\n","print(f\"Number of training samples for {sample_class}: {len(os.listdir(os.path.join(train_path, sample_class)))}\")\n","print(f\"Number of testing samples for {sample_class}: {len(os.listdir(os.path.join(test_path, sample_class)))}\")\n"],"metadata":{"id":"lv12o8ATgXZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def zip_folder(folder_path, zip_path):\n","    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n","        for root, _, files in os.walk(folder_path):\n","            for file in files:\n","                file_path = os.path.join(root, file)\n","                arcname = os.path.relpath(file_path, folder_path)\n","                zipf.write(file_path, arcname)\n","\n","\n","def download_zip(local_filename):\n","    with open(local_filename, 'wb') as file:\n","        file.write(response.content)\n"],"metadata":{"id":"V3Yk1zB6hL2c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["folder_to_zip1 = '/content/data/Dataset/train'\n","zip_file_path1 = '/content/train.zip'\n","folder_to_zip2 = '/content/data/Dataset/test'\n","zip_file_path2 = '/content/test.zip'\n","\n","zip_folder(folder_to_zip1, zip_file_path1)\n","zip_folder(folder_to_zip2, zip_file_path2)"],"metadata":{"id":"BoujtSdXhevP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["local_zip_file1 = '/downloads/train.zip'\n","local_zip_file2 = '/downloads/test.zip'\n","\n","download_zip(local_zip_file1)\n","download_zip(local_zip_file2)"],"metadata":{"id":"KgyzjLOMhVw3"},"execution_count":null,"outputs":[]}]}